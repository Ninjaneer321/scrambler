{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, CuDNNLSTM, CuDNNGRU, BatchNormalization, LocallyConnected2D, Permute, TimeDistributed, Bidirectional\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.layers.merge import _Merge\n",
    "import keras.losses\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import isolearn.keras as iso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sequence_logo_helper import dna_letter_at, plot_dna_logo\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n",
    "\n",
    "class EpochVariableCallback(Callback) :\n",
    "    \n",
    "    def __init__(self, my_variable, my_func) :\n",
    "        self.my_variable = my_variable       \n",
    "        self.my_func = my_func\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}) :\n",
    "        K.set_value(self.my_variable, self.my_func(K.get_value(self.my_variable), epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (15008, 1, 50, 4)\n",
      "x_test.shape = (512, 1, 50, 4)\n",
      "y_test.shape = (512, 50, 7)\n"
     ]
    }
   ],
   "source": [
    "#Define dataset/experiment name\n",
    "dataset_name = \"optimus5_synthetic_if_uorf_1_start_2_stop_variable_loc\"\n",
    "\n",
    "def one_hot_encode(df, col='utr', seq_len=50):\n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1], 'n':[0,0,0,0]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    vectors=np.empty([len(df),seq_len,4])\n",
    "    \n",
    "    # Iterate through UTRs and one-hot encode\n",
    "    for i,seq in enumerate(df[col].str[:seq_len]): \n",
    "        seq = seq.lower()\n",
    "        a = np.array([nuc_d[x] for x in seq])\n",
    "        vectors[i] = a\n",
    "    return vectors\n",
    "\n",
    "def one_hot_encode_gt(df, col='gt', seq_len=50):\n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'n':[1,0,0,0,0,0,0],'a':[0,1,0,0,0,0,0],'b':[0,0,1,0,0,0,0],'c':[0,0,0,1,0,0,0],'x':[0,0,0,0,1,0,0],'y':[0,0,0,0,0,1,0],'z':[0,0,0,0,0,0,1]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    vectors=np.empty([len(df),seq_len,7])\n",
    "    \n",
    "    # Iterate through UTRs and one-hot encode\n",
    "    for i,seq in enumerate(df[col].str[:seq_len]): \n",
    "        seq = seq.lower()\n",
    "        a = np.array([nuc_d[x] for x in seq])\n",
    "        vectors[i] = a\n",
    "    return vectors\n",
    "\n",
    "#Train data\n",
    "df_train = pd.read_csv(\"bottom5KIFuAUGTop5KIFuAUG.csv\")\n",
    "x_train = np.expand_dims(one_hot_encode(df_train), axis=1)\n",
    "\n",
    "#Test data\n",
    "df_test = pd.read_csv(\"optimus5_synthetic_if_uorf_1_start_2_stop_variable_loc.csv\")\n",
    "x_test = np.expand_dims(one_hot_encode(df_test), axis=1)\n",
    "y_test = one_hot_encode_gt(df_test)\n",
    "\n",
    "print(\"x_train.shape = \" + str(x_train.shape))\n",
    "print(\"x_test.shape = \" + str(x_test.shape))\n",
    "print(\"y_test.shape = \" + str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sequence template (APA Doubledope sublibrary)\n",
    "\n",
    "sequence_template = 'N' * 50\n",
    "\n",
    "sequence_mask = np.array([1 if sequence_template[j] == 'N' else 0 for j in range(len(sequence_template))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAABACAYAAAAH14HqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAsVJREFUeJzt3c1uzFEcx+Hvqb6Itkg1URYsLLq0dwWuwYqEnYid23ATylWQYGEpEcRSJA0JwqKNl3aOxTTpDyHGVIs8TzKLmfzn5De7T07OybTeewAAgKGJvR4AAAD+JgIZAAAKgQwAAIVABgCAQiADAEAhkAEAoBDIAABQCGQAACgEMgAAFAIZAAAKgQwAAIVABgCAQiADAEAhkAEAoBDIAABQCGQAACgEMgAAFAIZAAAKgQwAAIVABgCAQiADAEAhkAEAoBDIAABQCGQAACgEMgAAFAIZAAAKgQwAAIVABgCAQiADAEAhkAEAoBDIAABQCGQAACgEMgAAFAIZAAAKgQwAAIVABgCAQiADAEAhkAEAoBDIAABQCGQAACgEMgAAFAIZAAAKgQwAAIVABgCAYnLcBVrLZJK5rdd0kg9J3vWe9XHXBgCA3TZyILeWpSSXkpxJcjrJoSQPk7xMsp5kJslia1lIcqX33N25cQEA4M8aKZBby8kkD5IsbX10K8nF3rP2g+fbeOMBAMDuGvUM8iDJZnk/lZ9HtkAGAOCf0nrvo32hZTHJhWwfsVhK8iTJq2wfsVhIMp/kcu+5t5MDAwDAnzRyIH+3QEvL+f2DbMwlm9PJzdXFJO97z8Y3z+1LcjTJwQwv9M0k+ZThrnTP17vNj3rPp7EGAwCA3zDaJb2VdiDJcoahO5tkvd/Im3YnyeTHJEm/0ZaSHMtKJpJs5lx/vDD39vjszPS1iTY4leTQkfk3T5ePPbs/O7P2LsmgpQ8GfaK11tvnzampq2evv05uP9/B3wkAwG5orSU5nOREhqcKPiRZS3Ikw83RF0lW0/vGD9fYYyPtILfWxttuBgCAPdJ7/6X7cWMfsQAAgP+Jf9IDAIBCIAMAQCGQAQCgEMgAAFAIZAAAKAQyAAAUAhkAAAqBDAAAhUAGAIBCIAMAQPEFYO9l2T1+SwAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize background sequence distribution\n",
    "\n",
    "save_figs = False\n",
    "\n",
    "pseudo_count = 1.0\n",
    "\n",
    "x_mean = (np.sum(x_train, axis=(0, 1)) + pseudo_count) / (x_train.shape[0] + 4. * pseudo_count)\n",
    "x_mean_logits = np.log(x_mean / (1. - x_mean))\n",
    "\n",
    "plot_dna_logo(np.copy(x_mean), sequence_template=sequence_template, figsize=(10, 1), logo_height=1.0, plot_start=0, plot_end=50, plot_sequence_template=True, save_figs=save_figs, fig_name=\"benchmark_inclusion_\" + dataset_name + \"_background\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean conservation (bits) = 0.032049298346210106\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean training set conservation\n",
    "\n",
    "entropy = np.sum(x_mean * -np.log(x_mean), axis=-1) / np.log(2.0)\n",
    "conservation = 2.0 - entropy\n",
    "\n",
    "x_mean_conservation = np.sum(conservation) / np.sum(sequence_mask)\n",
    "\n",
    "print(\"Mean conservation (bits) = \" + str(x_mean_conservation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean KL Div against background (bits) = 1.9679329305814974\n"
     ]
    }
   ],
   "source": [
    "#Calculate mean training set kl-divergence against background\n",
    "\n",
    "x_train_clipped = np.clip(np.copy(x_train[:, 0, :, :]), 1e-8, 1. - 1e-8)\n",
    "\n",
    "kl_divs = np.sum(x_train_clipped * np.log(x_train_clipped / np.tile(np.expand_dims(x_mean, axis=0), (x_train_clipped.shape[0], 1, 1))), axis=-1) / np.log(2.0)\n",
    "\n",
    "x_mean_kl_divs = np.sum(kl_divs * sequence_mask, axis=-1) / np.sum(sequence_mask)\n",
    "x_mean_kl_div = np.mean(x_mean_kl_divs)\n",
    "\n",
    "print(\"Mean KL Div against background (bits) = \" + str(x_mean_kl_div))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "#Stochastic Binarized Neuron helper functions (Tensorflow)\n",
    "#ST Estimator code adopted from https://r2rt.com/beyond-binary-ternary-and-one-hot-neurons.html\n",
    "#See Github https://github.com/spitis/\n",
    "\n",
    "def st_sampled_softmax(logits):\n",
    "    with ops.name_scope(\"STSampledSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.squeeze(tf.multinomial(logits, 1), 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "def st_hardmax_softmax(logits):\n",
    "    with ops.name_scope(\"STHardmaxSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.argmax(nt_probs, 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "@ops.RegisterGradient(\"STMul\")\n",
    "def st_mul(op, grad):\n",
    "    return [grad, grad]\n",
    "\n",
    "#Gumbel Distribution Sampler\n",
    "def gumbel_softmax(logits, temperature=0.5) :\n",
    "    gumbel_dist = tf.contrib.distributions.RelaxedOneHotCategorical(temperature, logits=logits)\n",
    "    batch_dim = logits.get_shape().as_list()[0]\n",
    "    onehot_dim = logits.get_shape().as_list()[1]\n",
    "    return gumbel_dist.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PWM Masking and Sampling helper functions\n",
    "\n",
    "def mask_pwm(inputs) :\n",
    "    pwm, onehot_template, onehot_mask = inputs\n",
    "\n",
    "    return pwm * onehot_mask + onehot_template\n",
    "\n",
    "def sample_pwm_st(pwm_logits) :\n",
    "    n_sequences = K.shape(pwm_logits)[0]\n",
    "    seq_length = K.shape(pwm_logits)[2]\n",
    "\n",
    "    flat_pwm = K.reshape(pwm_logits, (n_sequences * seq_length, 4))\n",
    "    sampled_pwm = st_sampled_softmax(flat_pwm)\n",
    "\n",
    "    return K.reshape(sampled_pwm, (n_sequences, 1, seq_length, 4))\n",
    "\n",
    "def sample_pwm_gumbel(pwm_logits) :\n",
    "    n_sequences = K.shape(pwm_logits)[0]\n",
    "    seq_length = K.shape(pwm_logits)[2]\n",
    "\n",
    "    flat_pwm = K.reshape(pwm_logits, (n_sequences * seq_length, 4))\n",
    "    sampled_pwm = gumbel_softmax(flat_pwm, temperature=0.5)\n",
    "\n",
    "    return K.reshape(sampled_pwm, (n_sequences, 1, seq_length, 4))\n",
    "\n",
    "#Generator helper functions\n",
    "def initialize_sequence_templates(generator, sequence_templates, background_matrices) :\n",
    "\n",
    "    embedding_templates = []\n",
    "    embedding_masks = []\n",
    "    embedding_backgrounds = []\n",
    "\n",
    "    for k in range(len(sequence_templates)) :\n",
    "        sequence_template = sequence_templates[k]\n",
    "        onehot_template = iso.OneHotEncoder(seq_length=len(sequence_template))(sequence_template).reshape((1, len(sequence_template), 4))\n",
    "\n",
    "        for j in range(len(sequence_template)) :\n",
    "            if sequence_template[j] not in ['N', 'X'] :\n",
    "                nt_ix = np.argmax(onehot_template[0, j, :])\n",
    "                onehot_template[:, j, :] = -4.0\n",
    "                onehot_template[:, j, nt_ix] = 10.0\n",
    "            elif sequence_template[j] == 'X' :\n",
    "                onehot_template[:, j, :] = -1.0\n",
    "\n",
    "        onehot_mask = np.zeros((1, len(sequence_template), 4))\n",
    "        for j in range(len(sequence_template)) :\n",
    "            if sequence_template[j] == 'N' :\n",
    "                onehot_mask[:, j, :] = 1.0\n",
    "\n",
    "        embedding_templates.append(onehot_template.reshape(1, -1))\n",
    "        embedding_masks.append(onehot_mask.reshape(1, -1))\n",
    "        embedding_backgrounds.append(background_matrices[k].reshape(1, -1))\n",
    "\n",
    "    embedding_templates = np.concatenate(embedding_templates, axis=0)\n",
    "    embedding_masks = np.concatenate(embedding_masks, axis=0)\n",
    "    embedding_backgrounds = np.concatenate(embedding_backgrounds, axis=0)\n",
    "\n",
    "    generator.get_layer('template_dense').set_weights([embedding_templates])\n",
    "    generator.get_layer('template_dense').trainable = False\n",
    "\n",
    "    generator.get_layer('mask_dense').set_weights([embedding_masks])\n",
    "    generator.get_layer('mask_dense').trainable = False\n",
    "    \n",
    "    generator.get_layer('background_dense').set_weights([embedding_backgrounds])\n",
    "    generator.get_layer('background_dense').trainable = False\n",
    "\n",
    "#Generator construction function\n",
    "def build_sampler(batch_size, seq_length, n_classes=1, n_samples=1, sample_mode='st') :\n",
    "\n",
    "    #Initialize Reshape layer\n",
    "    reshape_layer = Reshape((1, seq_length, 4))\n",
    "    \n",
    "    #Initialize background matrix\n",
    "    onehot_background_dense = Embedding(n_classes, seq_length * 4, embeddings_initializer='zeros', name='background_dense')\n",
    "\n",
    "    #Initialize template and mask matrices\n",
    "    onehot_template_dense = Embedding(n_classes, seq_length * 4, embeddings_initializer='zeros', name='template_dense')\n",
    "    onehot_mask_dense = Embedding(n_classes, seq_length * 4, embeddings_initializer='ones', name='mask_dense')\n",
    "\n",
    "    #Initialize Templating and Masking Lambda layer\n",
    "    masking_layer = Lambda(mask_pwm, output_shape = (1, seq_length, 4), name='masking_layer')\n",
    "    background_layer = Lambda(lambda x: x[0] + x[1], name='background_layer')\n",
    "    \n",
    "    #Initialize PWM normalization layer\n",
    "    pwm_layer = Softmax(axis=-1, name='pwm')\n",
    "    \n",
    "    #Initialize sampling layers\n",
    "    sample_func = None\n",
    "    if sample_mode == 'st' :\n",
    "        sample_func = sample_pwm_st\n",
    "    elif sample_mode == 'gumbel' :\n",
    "        sample_func = sample_pwm_gumbel\n",
    "    \n",
    "    upsampling_layer = Lambda(lambda x: K.tile(x, [n_samples, 1, 1, 1]), name='upsampling_layer')\n",
    "    sampling_layer = Lambda(sample_func, name='pwm_sampler')\n",
    "    permute_layer = Lambda(lambda x: K.permute_dimensions(K.reshape(x, (n_samples, batch_size, 1, seq_length, 4)), (1, 0, 2, 3, 4)), name='permute_layer')\n",
    "    \n",
    "    def _sampler_func(class_input, raw_logits) :\n",
    "        \n",
    "        #Get Template and Mask\n",
    "        onehot_background = reshape_layer(onehot_background_dense(class_input))\n",
    "        onehot_template = reshape_layer(onehot_template_dense(class_input))\n",
    "        onehot_mask = reshape_layer(onehot_mask_dense(class_input))\n",
    "        \n",
    "        #Add Template and Multiply Mask\n",
    "        pwm_logits = masking_layer([background_layer([raw_logits, onehot_background]), onehot_template, onehot_mask])\n",
    "        \n",
    "        #Compute PWM (Nucleotide-wise Softmax)\n",
    "        pwm = pwm_layer(pwm_logits)\n",
    "        \n",
    "        #Tile each PWM to sample from and create sample axis\n",
    "        pwm_logits_upsampled = upsampling_layer(pwm_logits)\n",
    "        sampled_pwm = sampling_layer(pwm_logits_upsampled)\n",
    "        sampled_pwm = permute_layer(sampled_pwm)\n",
    "\n",
    "        sampled_mask = permute_layer(upsampling_layer(onehot_mask))\n",
    "        \n",
    "        return pwm_logits, pwm, sampled_pwm, onehot_mask, sampled_mask\n",
    "    \n",
    "    return _sampler_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Encoder and Decoder networks\n",
    "batch_size = 32\n",
    "seq_length = 50\n",
    "n_samples = 128\n",
    "sample_mode = 'st'\n",
    "#sample_mode = 'gumbel'\n",
    "\n",
    "#Load sampler\n",
    "sampler = build_sampler(batch_size, seq_length, n_classes=1, n_samples=n_samples, sample_mode=sample_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 50, 120)           3960      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 120)           115320    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 120)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 50, 120)           115320    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 120)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                240040    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 474,681\n",
      "Trainable params: 0\n",
      "Non-trainable params: 474,681\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load Predictor\n",
    "predictor_path = 'optimusRetrainedMain.hdf5'\n",
    "\n",
    "predictor_temp = load_model(predictor_path)\n",
    "\n",
    "predictor_temp.trainable = False\n",
    "predictor_temp.compile(optimizer=keras.optimizers.SGD(lr=0.1), loss='mean_squared_error')\n",
    "\n",
    "predictor_temp.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimus5 parameters\n",
    "seq_input_shape = (1, 50, 4)\n",
    "\n",
    "#Inputs\n",
    "seq_input = Input(shape=seq_input_shape)\n",
    "\n",
    "permute_layer = Lambda(lambda x: x[:, 0, ...])\n",
    "\n",
    "predictor = Model(\n",
    "    inputs=seq_input,\n",
    "    outputs=[\n",
    "        predictor_temp([permute_layer(seq_input)])\n",
    "    ]\n",
    ")\n",
    "\n",
    "predictor.trainable = False\n",
    "\n",
    "predictor.compile(\n",
    "    optimizer=keras.optimizers.SGD(lr=0.1),\n",
    "    loss='mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build scrambler model\n",
    "dummy_class = Input(shape=(1,), name='dummy_class')\n",
    "input_logits = Input(shape=(1, seq_length, 4), name='input_logits')\n",
    "\n",
    "pwm_logits, pwm, sampled_pwm, pwm_mask, sampled_mask = sampler(dummy_class, input_logits)\n",
    "\n",
    "scrambler_model = Model([input_logits, dummy_class], [pwm_logits, pwm, sampled_pwm, pwm_mask, sampled_mask])\n",
    "\n",
    "#Initialize Sequence Templates and Masks\n",
    "initialize_sequence_templates(scrambler_model, [sequence_template], [x_mean_logits])\n",
    "\n",
    "scrambler_model.trainable = False\n",
    "scrambler_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    loss='mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dummy_class (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "background_dense (Embedding)    (None, 1, 200)       200         dummy_class[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_logits (InputLayer)       (None, 1, 50, 4)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 50, 4)     0           background_dense[0][0]           \n",
      "                                                                 template_dense[0][0]             \n",
      "                                                                 mask_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "template_dense (Embedding)      (None, 1, 200)       200         dummy_class[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mask_dense (Embedding)          (None, 1, 200)       200         dummy_class[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "background_layer (Lambda)       (None, 1, 50, 4)     0           input_logits[0][0]               \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_layer (Lambda)          (None, 1, 50, 4)     0           background_layer[0][0]           \n",
      "                                                                 reshape_1[1][0]                  \n",
      "                                                                 reshape_1[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_layer (Lambda)       (None, 1, 50, 4)     0           masking_layer[0][0]              \n",
      "                                                                 reshape_1[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pwm_sampler (Lambda)            (None, 1, None, 4)   0           upsampling_layer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pwm (Softmax)                   (None, 1, 50, 4)     0           masking_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_layer (Lambda)          (32, 128, 1, 50, 4)  0           pwm_sampler[0][0]                \n",
      "                                                                 upsampling_layer[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 600\n",
      "Trainable params: 0\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "scrambler_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_names = [\n",
    "    \"scrambler_optimus5_synthetic_if_uorf_1_start_2_stop_variable_loc_importance_scores_test.npy\",\n",
    "    \"perturbation_optimus5_synthetic_if_uorf_1_start_2_stop_variable_loc_importance_scores_test.npy\"\n",
    "]\n",
    "\n",
    "model_names =[\n",
    "    \"scrambler\",\n",
    "    \"perturbation\"\n",
    "]\n",
    "\n",
    "model_importance_scores_test = [np.load(file_name) for file_name in file_names]\n",
    "\n",
    "for model_i in range(len(model_names)) :\n",
    "    if model_importance_scores_test[model_i].shape[-1] > 1 :\n",
    "        model_importance_scores_test[model_i] = np.sum(model_importance_scores_test[model_i], axis=-1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 1s 2ms/step\n",
      "Benchmarking model 'scrambler'...\n",
      "Feature quantile = 0.76\n",
      "Processing example 0...\n",
      "Processing example 100...\n",
      "Processing example 200...\n",
      "Processing example 300...\n",
      "Processing example 400...\n",
      "Processing example 500...\n",
      "Feature quantile = 0.82\n",
      "Processing example 0...\n",
      "Processing example 100...\n",
      "Processing example 200...\n",
      "Processing example 300...\n",
      "Processing example 400...\n",
      "Processing example 500...\n",
      "Feature quantile = 0.88\n",
      "Processing example 0...\n",
      "Processing example 100...\n",
      "Processing example 200...\n",
      "Processing example 300...\n",
      "Processing example 400...\n",
      "Processing example 500...\n",
      "Benchmarking model 'perturbation'...\n",
      "Feature quantile = 0.76\n",
      "Processing example 0...\n",
      "Processing example 100...\n",
      "Processing example 200...\n",
      "Processing example 300...\n",
      "Processing example 400...\n",
      "Processing example 500...\n",
      "Feature quantile = 0.82\n",
      "Processing example 0...\n",
      "Processing example 100...\n",
      "Processing example 200...\n",
      "Processing example 300...\n",
      "Processing example 400...\n",
      "Processing example 500...\n",
      "Feature quantile = 0.88\n",
      "Processing example 0...\n",
      "Processing example 100...\n",
      "Processing example 200...\n",
      "Processing example 300...\n",
      "Processing example 400...\n",
      "Processing example 500...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_quantiles = [0.76, 0.82, 0.88]\n",
    "\n",
    "on_state_logit_val = 50.\n",
    "\n",
    "dummy_test = np.zeros((x_test.shape[0], 1))\n",
    "x_test_logits = 2. * x_test - 1.\n",
    "\n",
    "aparent_l_test = np.zeros((x_test.shape[0], 13))\n",
    "aparent_l_test[:, 4] = 1.\n",
    "\n",
    "aparent_d_test = np.ones((x_test.shape[0], 1))\n",
    "\n",
    "y_pred_ref = predictor.predict([x_test], batch_size=32, verbose=True)\n",
    "\n",
    "_, _, _, pwm_mask, sampled_mask = scrambler_model.predict([x_test_logits, dummy_test], batch_size=batch_size)\n",
    "\n",
    "model_mses = []\n",
    "\n",
    "for model_i in range(len(model_names)) :\n",
    "    \n",
    "    print(\"Benchmarking model '\" + str(model_names[model_i]) + \"'...\")\n",
    "    \n",
    "    feature_quantile_mses = []\n",
    "    \n",
    "    for feature_quantile_i, feature_quantile in enumerate(feature_quantiles) :\n",
    "        \n",
    "        print(\"Feature quantile = \" + str(feature_quantile))\n",
    "    \n",
    "        if len(model_importance_scores_test[model_i].shape) >= 5 :\n",
    "            importance_scores_test = np.abs(model_importance_scores_test[model_i][feature_quantile_i, ...])\n",
    "        else :\n",
    "            importance_scores_test = np.abs(model_importance_scores_test[model_i])\n",
    "        \n",
    "        n_to_test = importance_scores_test.shape[0] // batch_size * batch_size\n",
    "        importance_scores_test = importance_scores_test[:n_to_test]\n",
    "        \n",
    "        importance_scores_test *= np.expand_dims(np.max(pwm_mask[:n_to_test], axis=-1), axis=-1)\n",
    "\n",
    "        quantile_vals = np.quantile(importance_scores_test, axis=(1, 2, 3), q=feature_quantile, keepdims=True)\n",
    "        quantile_vals = np.tile(quantile_vals, (1, importance_scores_test.shape[1], importance_scores_test.shape[2], importance_scores_test.shape[3]))\n",
    "\n",
    "        top_logits_test = np.zeros(importance_scores_test.shape)\n",
    "        top_logits_test[importance_scores_test > quantile_vals] = on_state_logit_val\n",
    "        \n",
    "        top_logits_test = np.tile(top_logits_test, (1, 1, 1, 4)) * x_test_logits[:n_to_test]\n",
    "\n",
    "        _, _, samples_test, _, _ = scrambler_model.predict([top_logits_test, dummy_test[:n_to_test]], batch_size=batch_size)\n",
    "\n",
    "        mses = []\n",
    "        for data_ix in range(samples_test.shape[0]) :\n",
    "\n",
    "            if data_ix % 100 == 0 :\n",
    "                print(\"Processing example \" + str(data_ix) + \"...\")\n",
    "\n",
    "            y_pred_var_samples = predictor.predict([samples_test[data_ix, ...]], batch_size=n_samples)[:, 0]\n",
    "            y_pred_ref_samples = np.tile(y_pred_ref[data_ix, :], (n_samples,))\n",
    "            \n",
    "            mse = np.mean((y_pred_ref_samples - y_pred_var_samples)**2)\n",
    "\n",
    "            mses.append(mse)\n",
    "\n",
    "        mses = np.array(mses)\n",
    "        \n",
    "        feature_quantile_mses.append(mses)\n",
    "\n",
    "    model_mses.append(feature_quantile_mses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names =[\n",
    "    \"scrambler\",\n",
    "    \"perturbation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    \n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "benchmark_name = \"benchmark_inclusion_optimus5_synthetic_if_uorf_1_start_2_stop_variable_loc\"\n",
    "\n",
    "save_figs = False\n",
    "\n",
    "width = 0.2\n",
    "\n",
    "max_y_val = None\n",
    "\n",
    "cm = plt.get_cmap('viridis_r')\n",
    "\n",
    "shades = [0.4, 0.6, 0.8, 1]\n",
    "\n",
    "quantiles = [0.5, 0.8, 0.9, 0.95]\n",
    "\n",
    "all_colors = plt.rcParams['axes.prop_cycle'].by_key()['color'] + plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "model_colors = {model_names[i]: all_colors[i] for i in range(len(model_names))}\n",
    "\n",
    "results = np.zeros((len(quantiles), len(model_names), 1))\n",
    "\n",
    "for i in range(1, len(feature_quantiles) + 1) :\n",
    "    for j in range(len(model_names)):\n",
    "        mse_samples = model_mses[j][i-1]\n",
    "\n",
    "        for l in range(len(quantiles)):\n",
    "            quantile = quantiles[l]\n",
    "\n",
    "            results[l, j, 0] = np.quantile(mse_samples, q=quantile)\n",
    "\n",
    "    xs = range(len(model_names))\n",
    "    xs = [xi + i*width for xi in xs]\n",
    "    \n",
    "    for j in range(len(model_names)) :\n",
    "        for l in range(len(quantiles)) :\n",
    "            model_name = model_names[j]\n",
    "            c = model_colors[model_name]\n",
    "            val = results[l, j, 0]\n",
    "            \n",
    "            if i == 1 and j == 0 :\n",
    "                lbl = \"$%i^{th}$ Perc.\" % int(100*quantiles[l])\n",
    "            else :\n",
    "                lbl=None\n",
    "            \n",
    "            if l == 0 :\n",
    "                plt.bar(xs[j], val, width=width, color=lighten_color(c, shades[l]), edgecolor='k', linewidth=1, label=lbl, zorder=l+1)\n",
    "            else :\n",
    "                prev_val = results[l-1, j].mean(axis=-1)\n",
    "                plt.bar(xs[j],val-prev_val, width=width, bottom = prev_val, color=lighten_color(c, shades[l]), edgecolor='k', linewidth=1, label=lbl, zorder=l+1)\n",
    "    \n",
    "            if l == len(quantiles) - 1 and (max_y_val is None or val < 0.95 * max_y_val) :\n",
    "                plt.text(xs[j], val, \"Top\\n\" + str(int(100 - 100 * feature_quantiles[i-1])) + \"%\", horizontalalignment='center', verticalalignment='bottom', fontdict={ 'family': 'serif', 'color':  'black', 'weight': 'bold', 'size': 10 })\n",
    "    \n",
    "    prev_results = results\n",
    "\n",
    "plt.xticks([i + 2.5*width for i in range(len(model_names))])\n",
    "\n",
    "all_lbls = [model_names[j].upper() for j in range(len(model_names))]\n",
    "plt.gca().set_xticklabels(all_lbls, rotation=60)\n",
    "\n",
    "plt.ylabel(\"Test Set KL-Divergence\")\n",
    "\n",
    "#max_y_val = np.max(results) * 1.1\n",
    "\n",
    "if max_y_val is not None :\n",
    "    plt.ylim([0, max_y_val])\n",
    "\n",
    "plt.grid(True)\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.gca().grid(color='gray', alpha=0.2)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().yaxis.set_ticks_position('left')\n",
    "plt.gca().xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.legend(fontsize=12, frameon=True, loc='upper left')\n",
    "leg = plt.gca().get_legend()\n",
    "for l in range(len(quantiles)):\n",
    "    leg.legendHandles[l].set_color(lighten_color(all_colors[7], shades[l]))\n",
    "    leg.legendHandles[l].set_edgecolor('k')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs :\n",
    "    plt.savefig(benchmark_name + \".png\", dpi=300, transparent=True)\n",
    "    plt.savefig(benchmark_name + \".eps\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
